{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import requests\n",
    "from config import SETTINGS\n",
    "from geo.Geoserver import Geoserver\n",
    "from minio import Minio\n",
    "from minio.error import InvalidResponseError\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading GeoTiffs into GeoNode\n",
    "\n",
    "This notebook illustrates how to load GeoTiffs into GeoServer/GeoNode using GDAL for data processing and the [GeoNode API](https://docs.geonode.org/en/master/devel/index.html). [Geoserver-Rest](https://geoserver-rest.readthedocs.io/en/latest/advanced_uses.html) may also be useful.\n",
    "\n",
    "## 1. Files to process\n",
    "\n",
    "The raw mosaics are not well optimised for display online. The first steps are therefore to convert them to Cloud Optimised Geotiffs (COGs), using either lossless or lossy compressions and internal tiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing image mosaics\n",
    "data_fold = r\"/home/notebook/shared-seabee-ns9879k/all-mosaics\"\n",
    "\n",
    "# Output folder for Cloud Optimised Geotiffs (COGs)\n",
    "cog_dir = r\"/home/notebook/cogs/\"\n",
    "\n",
    "# Set compression type for COGs. If lossless = True, 'LZW' will be used.\n",
    "# Otherwise, JPEG compression with QUALITY=50 and conversion to 8-bit\n",
    "# will be used (this creates much smaller files, but also loses information).\n",
    "lossless = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw mosaic sizes:\n",
      "Olberg_RGB_45m_Re_reprocess_dsm.tif                              : 721.52 MB\n",
      "Olberg_RGB_45m_Re_reprocess_transparent_mosaic_group1.tif        : 553.21 MB\n",
      "ne_akeroya_rgb_ms_5cm_compress_8bit.tif                          : 731.09 MB\n",
      "akeroya_ms_10cm_8bit_compress.tif                                : 648.21 MB\n"
     ]
    }
   ],
   "source": [
    "# Get list of files to process\n",
    "search_path = os.path.join(data_fold, \"*.tif\")\n",
    "flist = glob.glob(search_path)\n",
    "\n",
    "# Print file sizes\n",
    "print(\"Raw mosaic sizes:\")\n",
    "for fpath in flist:\n",
    "    fname = os.path.basename(fpath)\n",
    "    fsize_mb = os.path.getsize(fpath) / 1e6\n",
    "    print(f\"{fname:<65}: {fsize_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optimising files for display online\n",
    "\n",
    "The blog post [here](http://blog.cleverelephant.ca/2015/02/geotiff-compression-for-dummies.html) from Paul Ramsey provides a useful staring point for optimising GeoTiffs. Note that, for very large files, the [GeoServer documentation](https://docs.geoserver.org/stable/en/user/tutorials/imagepyramid/imagepyramid.html) recommends building **external image pyramids** rather than **internal overview layers**. Some example bash scripts for building external pyramids are [here](https://www.ianturton.com/tutorials/bluemarble.html). However, loading COGs with internal overviews is easier to automate via the Python API and it's what Paul Ramsey recommends, so we'll test this first.\n",
    "\n",
    "**Note:** Using `JPEG` compression (`lossless = False` above) will achieve the maximum reduction in file size. This is OK for visualisation online (e.g. for displaying datasets in GeoNode), but the resulting files **must not be used for machine learning**. JPEG compression is lossy and the JPEG format only supports 8-bit data (i.e. other bit depths must be converted). **For the ML we should always work with the original resolution files, saved with `LZW` compression**, which is lossless. However, using `JPEG` compression for visualisation substantially reduces file sizes, giving a smoother user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning 1: for band 1, nodata value has been clamped to 0, the original value being out of range.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 17544, 23960\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 17544, 23960\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 31328, 17859\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 26343, 16220\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "cog_list = []\n",
    "for fpath in flist:\n",
    "    fname = os.path.basename(fpath)\n",
    "    cog_path = os.path.join(cog_dir, os.path.splitext(fname)[0] + \"_cog.tif\")\n",
    "    cog_list.append(cog_path)\n",
    "    if lossless:\n",
    "        # Use LZW\n",
    "        cmd = [\n",
    "            \"gdal_translate\",\n",
    "            \"-of\",\n",
    "            \"COG\",\n",
    "            \"-co\",\n",
    "            \"COMPRESS=LZW\",\n",
    "            fpath,\n",
    "            cog_path,\n",
    "        ]\n",
    "    else:\n",
    "        # Use convert to 8-bit and JPEG with 50% quality\n",
    "        cmd = [\n",
    "            \"gdal_translate\",\n",
    "            \"-of\",\n",
    "            \"COG\",\n",
    "            \"-ot\",\n",
    "            \"Byte\",\n",
    "            \"-co\",\n",
    "            \"COMPRESS=JPEG\",\n",
    "            \"-co\",\n",
    "            \"QUALITY=50\",\n",
    "            fpath,\n",
    "            cog_path,\n",
    "        ]\n",
    "    subprocess.check_call(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get processed file sizes (including all overview layers etc.)\n",
    "print(\"COG mosaic sizes:\")\n",
    "for cog_path in cog_list:\n",
    "    fname = os.path.basename(cog_path)\n",
    "    fsize_mb = os.path.getsize(cog_path) / 1e6\n",
    "    print(f\"{fname:<65}: {fsize_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files sizes above using JPEG compression are *much* smaller than the originals (especially because the COGs include internally tiles overviews).\n",
    "\n",
    "## 3. Upload COGs via the GeoNode API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://geonode.seabee.sigma2.no/api/v2/uploads/upload\"\n",
    "headers = {\"Authorization\": f\"Bearer {SETTINGS.GEONODE_TOKEN}\"}\n",
    "for fpath in tqdm(cog_list):\n",
    "    fname = os.path.split(fpath)[1]\n",
    "    files = [\n",
    "        (\n",
    "            \"base_file\",\n",
    "            (\n",
    "                fname,\n",
    "                open(fpath, \"rb\"),\n",
    "                \"application/octet-stream\",\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    response = requests.request(\"POST\", base_url, headers=headers, files=files)\n",
    "    response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add files using `geoserver-rest`\n",
    "\n",
    "[Geoserver-Rest](https://geoserver-rest.readthedocs.io/en/latest/advanced_uses.html) offers direct access to workspaces on GeoServer and it's much nicer to use than the GeoNode API. An alternative and faster/more reliable approach for adding data to GeoNode is therefore to use `geoserver-rest`, as illustrated in the code below. However, to get new datasets to show up in GeoNode it is necessary to run either `geonode updatelayers` or `python manage.py updatelayers` from the GeoNode shell (sometimes called the Django shell). I *think* this can only be done programatically from within the GeoNode container (i.e. it's not possible to call this from the Hub), however, it looks as though it can be configured via the GeoNode admin panel under\n",
    "\n",
    "    Home > Management Commands Over HTTP > Management command jobs\n",
    "\n",
    "With a bit more research, this may be the best way of getting data into GeoNode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Authernticate with GeoServer\n",
    "# geo = Geoserver(\n",
    "#     \"https://geonode.seabee.sigma2.no/geoserver\",\n",
    "#     username=SETTINGS.GEOSERVER_USER,\n",
    "#     password=SETTINGS.GEOSERVER_PASSWORD,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upload COGs to GeoServer\n",
    "# workspace = \"geonode\"\n",
    "\n",
    "# search_path = os.path.join(cog, \"*.tif\")\n",
    "# flist = glob.glob(search_path)\n",
    "# for fpath in flist:\n",
    "#     fname = os.path.basename(fpath)\n",
    "#     layer_name = os.path.splitext(fname)[0]\n",
    "\n",
    "#     # Will overwrite layer if it exists\n",
    "#     status = geo.create_coveragestore(\n",
    "#         layer_name=layer_name, path=fpath, workspace=workspace\n",
    "#     )\n",
    "#     print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save COGs on MinIO\n",
    "\n",
    "The final step is to transfer the COGs to MinIO for long-term storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to MinIO\n",
    "sigma2_client = Minio(\n",
    "    \"storage.seabee.sigma2.no\",\n",
    "    access_key=SETTINGS.ACCESS_ID,\n",
    "    secret_key=SETTINGS.SECRET_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"all-mosaics\"\n",
    "found = sigma2_client.bucket_exists(bucket)\n",
    "if not found:\n",
    "    sigma2_client.make_bucket(bucket)\n",
    "\n",
    "for fpath in tqdm(cog_list):\n",
    "    fname = os.path.split(fpath)[1]\n",
    "    try:\n",
    "        with open(fpath, \"rb\") as file_data:\n",
    "            file_stat = os.stat(fpath)\n",
    "            sigma2_client.put_object(\n",
    "                bucket, f\"cloud-optimised/{fname}\", file_data, file_stat.st_size\n",
    "            )\n",
    "    except InvalidResponseError as err:\n",
    "        print(err)\n",
    "    os.remove(fpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
